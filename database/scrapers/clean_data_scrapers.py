"""
SCRIPT DE NETTOYAGE COMPLET - PROJET ID IMMOBILIER
Prend en compte :
- Les 3 niveaux de champs (Essentiels, Utiles, Bonus)
- La structure compl√®te de la base de donn√©es
- Tous les enrichissements n√©cessaires
"""

import pandas as pd
import numpy as np
import re
from datetime import datetime
import json


class IDImmobilierCleaner:
    """
    Nettoyeur complet pour le projet ID Immobilier
    Respecte les 3 niveaux de champs et la structure SQL
    """
    
    def __init__(self):
        # Configuration
        self.surface_lot_standard = 350  # 1 lot standard au Togo ‚âà 350 m¬≤
        
        # Liste des quartiers de Lom√© (√† compl√©ter)
        self.quartiers_lome = [
            'adakpam√©', 'adidogom√©', 'akodess√©wa', 'adeticop√©', 'akodessewa',
            'anfoin', 'av√©dji', 'djidjol√©', 'no√®p√©', 'kpala', 'kpalim√©',
            'zangu√©ra', 'wonyom√©', 'nanegb√©', 'totsi', 'b√®', 'agoe',
            'hedziranawoe', 'adewui', 'kagom√©', 'tokoin', 'nyekonakpoe'
        ]
        
        # Mapping des champs selon les 3 niveaux
        self.niveaux_champs = {
            'niveau_1_essentiels': [
                'id',
                'marketplace_listing_title',
                'custom_title',
                'listing_price/amount',
                'location/reverse_geocode/city',
                'listingUrl',
                'is_sold',
                'is_live'
            ],
            'niveau_2_utiles': [
                'primary_listing_photo/photo_image_url',
                'marketplace_listing_category_id',
                'location/reverse_geocode/state'
            ],
            'niveau_3_bonus': [
                'facebookUrl',
                'listing_price/formatted_amount',
                'location/reverse_geocode/city_page/display_name',
                'is_pending',
                'is_hidden'
            ]
        }
    
    # ============================================
    # NIVEAU 1 : EXTRACTION DES CHAMPS ESSENTIELS
    # ============================================
    
    def extraire_surface(self, titre):
        """
        Extraire la surface depuis le titre
        Patterns support√©s : 1/4 lot, 1 lot, 350 m¬≤
        """
        if not titre or pd.isna(titre):
            return None
        
        titre = str(titre).lower()
        
        # Pattern 1: "1/4 de lot", "1/2 lot", "1/8 lot"
        match = re.search(r'(\d+)/(\d+)\s*(?:de\s*)?lots?', titre)
        if match:
            numerateur = int(match.group(1))
            denominateur = int(match.group(2))
            return (numerateur / denominateur) * self.surface_lot_standard
        
        # Pattern 2: "1 lot", "2 lots", "1lot"
        match = re.search(r'(\d+)\s*lots?', titre)
        if match:
            nb_lots = int(match.group(1))
            return nb_lots * self.surface_lot_standard
        
        # Pattern 3: "350 m¬≤", "350m2", "350 m√®tres carr√©s"
        match = re.search(r'(\d+)\s*(?:m[¬≤2]|m√®tres?\s*carr√©s?)', titre)
        if match:
            return int(match.group(1))
        
        # Pattern 4: "1lot et 1/4" (exemple: "1lot et 1/4 √† Nanegbe")
        match = re.search(r'(\d+)\s*lots?\s*et\s*(\d+)/(\d+)', titre)
        if match:
            lots_entiers = int(match.group(1))
            numerateur = int(match.group(2))
            denominateur = int(match.group(3))
            return (lots_entiers + numerateur / denominateur) * self.surface_lot_standard
        
        return None
    
    def extraire_quartier(self, titre):
        """Extraire le quartier depuis le titre"""
        if not titre or pd.isna(titre):
            return 'Non sp√©cifi√©'
        
        titre_lower = str(titre).lower()
        
        # Rechercher chaque quartier connu
        for quartier in self.quartiers_lome:
            if quartier in titre_lower:
                return quartier.capitalize()
        
        return 'Non sp√©cifi√©'
    
    def nettoyer_prix(self, prix, titre):
        """
        Nettoyer et valider le prix
        G√®re les prix aberrants et tente extraction depuis le titre
        """
        # Convertir en float si n√©cessaire
        try:
            prix = float(prix) if pd.notna(prix) else 0
        except:
            prix = 0
        
        # Si prix invalide, tenter extraction depuis titre
        if pd.isna(prix) or prix <= 0 or prix < 100000:
            if titre and not pd.isna(titre):
                # Pattern: "3,500,000" ou "3 500 000" ou "3500000"
                match = re.search(r'(\d{1,3}(?:[,\s]\d{3})+)\s*(?:fcfa|cfa|f)?', 
                                str(titre).lower())
                if match:
                    prix_str = match.group(1).replace(',', '').replace(' ', '')
                    try:
                        prix = float(prix_str)
                    except:
                        pass
                
                # Pattern: "X millions" ou "X M"
                match = re.search(r'(\d+(?:\.\d+)?)\s*(?:millions?|m)\s*(?:fcfa|cfa|f)?', 
                                str(titre).lower())
                if match:
                    prix = float(match.group(1)) * 1000000
        
        # Filtrer les prix aberrants (< 100 000 FCFA pour un terrain)
        if prix > 0 and prix < 100000:
            return None
        
        return prix if prix > 0 else None
    
    def identifier_type_bien(self, titre):
        """Identifier le type de bien immobilier"""
        if not titre or pd.isna(titre):
            return 'Inconnu'
        
        titre_lower = str(titre).lower()
        
        # Ordre de priorit√© pour √©viter les faux positifs
        if 'terrain' in titre_lower:
            return 'Terrain'
        elif any(word in titre_lower for word in ['villa', 'duplex']):
            return 'Villa'
        elif 'maison' in titre_lower:
            return 'Maison'
        elif any(word in titre_lower for word in ['appartement', 'studio', 'f1', 'f2', 'f3', 'f4']):
            return 'Appartement'
        elif 'immeuble' in titre_lower:
            return 'Immeuble'
        elif 'bureau' in titre_lower or 'commercial' in titre_lower:
            return 'Commercial'
        
        # Par d√©faut pour Facebook Marketplace recherche terrain
        return 'Terrain'
    
    def identifier_type_offre(self, titre):
        """Identifier le type d'offre (Vente ou Location)"""
        if not titre or pd.isna(titre):
            return 'Vente'
        
        titre_lower = str(titre).lower()
        
        if any(word in titre_lower for word in ['louer', 'location', '√† louer', 'en location']):
            return 'Location'
        
        return 'Vente'
    
    # ============================================
    # NIVEAU 2 : ENRICHISSEMENT DES DONN√âES
    # ============================================
    
    def generer_titre_complet(self, row):
        """G√©n√©rer un titre complet en combinant les champs disponibles"""
        titre_parts = []
        
        if pd.notna(row.get('marketplace_listing_title')):
            titre_parts.append(str(row['marketplace_listing_title']))
        
        if pd.notna(row.get('custom_title')):
            titre_parts.append(str(row['custom_title']))
        
        return ' '.join(titre_parts).strip() if titre_parts else 'Sans titre'
    
    def extraire_ville(self, row):
        """Extraire la ville avec fallback"""
        # Priorit√© 1: location/reverse_geocode/city
        if pd.notna(row.get('location/reverse_geocode/city')):
            return str(row['location/reverse_geocode/city'])
        
        # Priorit√© 2: location/reverse_geocode/city_page/display_name
        if pd.notna(row.get('location/reverse_geocode/city_page/display_name')):
            display = str(row['location/reverse_geocode/city_page/display_name'])
            return display.split(',')[0].strip()  # "Lom√©, Togo" -> "Lom√©"
        
        return 'Lom√©'  # Par d√©faut
    
    def determiner_statut(self, row):
        """D√©terminer le statut de l'annonce"""
        if row.get('is_sold') == 'true' or row.get('is_sold') == True:
            return 'Vendue'
        elif row.get('is_live') == 'true' or row.get('is_live') == True:
            return 'Active'
        elif row.get('is_pending') == 'true' or row.get('is_pending') == True:
            return 'En attente'
        elif row.get('is_hidden') == 'true' or row.get('is_hidden') == True:
            return 'Masqu√©e'
        else:
            return 'Inconnue'
    
    # ============================================
    # FONCTION PRINCIPALE DE NETTOYAGE
    # ============================================
    
    def nettoyer_dataset(self, df):
        """
        Nettoyer le dataset complet
        Retourne un DataFrame avec la structure de la base de donn√©es
        """
        
        print("="*60)
        print("üöÄ NETTOYAGE DATASET - PROJET ID IMMOBILIER")
        print("="*60)
        print(f"üìä Donn√©es initiales: {len(df)} lignes\n")
        
        # Cr√©er DataFrame de travail
        df_clean = df.copy()
        
        # ============================================
        # √âTAPE 1 : CHAMPS NIVEAU 1 (ESSENTIELS)
        # ============================================
        print("üîπ √âTAPE 1 : Extraction des champs essentiels")
        
        # 1.1 Titre complet
        df_clean['titre_complet'] = df_clean.apply(self.generer_titre_complet, axis=1)
        print("   ‚úì Titres g√©n√©r√©s")
        
        # 1.2 ID
        df_clean['id_bien'] = df_clean['id'].astype(str)
        print("   ‚úì ID extraits")
        
        # 1.3 Prix
        df_clean['prix_fcfa'] = df_clean.apply(
            lambda row: self.nettoyer_prix(
                row.get('listing_price/amount'), 
                row['titre_complet']
            ), axis=1
        )
        print(f"   ‚úì Prix nettoy√©s ({df_clean['prix_fcfa'].notna().sum()}/{len(df_clean)} valides)")
        
        # 1.4 Ville
        df_clean['ville'] = df_clean.apply(self.extraire_ville, axis=1)
        print("   ‚úì Villes extraites")
        
        # 1.5 URL
        df_clean['url_annonce'] = df_clean['listingUrl'].fillna('')
        print("   ‚úì URLs conserv√©es")
        
        # 1.6 Statut
        df_clean['statut'] = df_clean.apply(self.determiner_statut, axis=1)
        print("   ‚úì Statuts d√©termin√©s")
        
        # ============================================
        # √âTAPE 2 : ENRICHISSEMENT (EXTRACTION)
        # ============================================
        print("\nüîπ √âTAPE 2 : Enrichissement des donn√©es")
        
        # 2.1 Surface
        df_clean['surface_m2'] = df_clean['titre_complet'].apply(self.extraire_surface)
        surfaces_valides = df_clean['surface_m2'].notna().sum()
        print(f"   ‚úì Surfaces extraites ({surfaces_valides}/{len(df_clean)} valides)")
        
        # 2.2 Quartier
        df_clean['quartier'] = df_clean['titre_complet'].apply(self.extraire_quartier)
        quartiers_trouves = (df_clean['quartier'] != 'Non sp√©cifi√©').sum()
        print(f"   ‚úì Quartiers identifi√©s ({quartiers_trouves}/{len(df_clean)} trouv√©s)")
        
        # 2.3 Type de bien
        df_clean['type_bien'] = df_clean['titre_complet'].apply(self.identifier_type_bien)
        print("   ‚úì Types de biens identifi√©s")
        
        # 2.4 Type d'offre
        df_clean['type_offre'] = df_clean['titre_complet'].apply(self.identifier_type_offre)
        print("   ‚úì Types d'offres identifi√©s")
        
        # 2.5 Prix au m¬≤ (INDICATEUR CL√â)
        df_clean['prix_m2'] = df_clean.apply(
            lambda row: round(row['prix_fcfa'] / row['surface_m2'], 2)
            if pd.notna(row['surface_m2']) and row['surface_m2'] > 0 
               and pd.notna(row['prix_fcfa']) and row['prix_fcfa'] > 0
            else None,
            axis=1
        )
        prix_m2_valides = df_clean['prix_m2'].notna().sum()
        print(f"   ‚úì Prix au m¬≤ calcul√©s ({prix_m2_valides}/{len(df_clean)} valides)")
        
        # ============================================
        # √âTAPE 3 : CHAMPS NIVEAU 2 & 3 (UTILES/BONUS)
        # ============================================
        print("\nüîπ √âTAPE 3 : Ajout des champs compl√©mentaires")
        
        # Source des donn√©es
        df_clean['source'] = 'Facebook Marketplace'
        
        # Date de collecte
        df_clean['date_collecte'] = datetime.now().strftime('%Y-%m-%d')
        
        # Coordonn√©es GPS (√† enrichir ult√©rieurement)
        df_clean['latitude'] = None
        df_clean['longitude'] = None
        
        # Date de publication (√† extraire si disponible)
        df_clean['date_publication'] = None
        
        # Photo (NIVEAU 2 - UTILE)
        df_clean['url_photo'] = df_clean.get('primary_listing_photo/photo_image_url', '')
        
        print("   ‚úì Champs compl√©mentaires ajout√©s")
        
        # ============================================
        # √âTAPE 4 : FILTRAGE DES DONN√âES VALIDES
        # ============================================
        print("\nüîπ √âTAPE 4 : Filtrage des donn√©es valides")
        
        # Crit√®res de validit√© pour ID Immobilier
        df_valide = df_clean[
            (df_clean['prix_fcfa'].notna()) &
            (df_clean['surface_m2'].notna()) &
            (df_clean['prix_fcfa'] > 0) &
            (df_clean['surface_m2'] > 0) &
            (df_clean['prix_m2'].notna())
        ].copy()
        
        print(f"   ‚úì Donn√©es valides: {len(df_valide)} ({len(df_valide)/len(df)*100:.1f}%)")
        
        # ============================================
        # √âTAPE 5 : STATISTIQUES
        # ============================================
        print("\n" + "="*60)
        print("üìä STATISTIQUES FINALES")
        print("="*60)
        
        if len(df_valide) > 0:
            print(f"Prix moyen au m¬≤:     {df_valide['prix_m2'].mean():,.0f} FCFA")
            print(f"Prix m√©dian au m¬≤:    {df_valide['prix_m2'].median():,.0f} FCFA")
            print(f"Surface moyenne:      {df_valide['surface_m2'].mean():.0f} m¬≤")
            print(f"Prix moyen total:     {df_valide['prix_fcfa'].mean():,.0f} FCFA")
            
            print(f"\nüìç R√©partition par type de bien:")
            print(df_valide['type_bien'].value_counts())
            
            print(f"\nüìã R√©partition par type d'offre:")
            print(df_valide['type_offre'].value_counts())
            
            print(f"\nüèôÔ∏è Top 10 quartiers:")
            quartiers = df_valide[df_valide['quartier'] != 'Non sp√©cifi√©']['quartier'].value_counts().head(10)
            print(quartiers)
        else:
            print("‚ö†Ô∏è Aucune donn√©e valide apr√®s nettoyage")
        
        print("="*60)
        
        return df_valide
    
    # ============================================
    # EXPORT POUR BASE DE DONN√âES
    # ============================================
    
    def exporter_pour_bdd(self, df_clean, format='csv'):
        """
        Exporter selon la structure de la base de donn√©es
        Structure SQL d√©finie dans le TDR
        """
        
        # Colonnes finales selon la structure SQL
        colonnes_bdd = [
            'id_bien',              # VARCHAR(50) PRIMARY KEY
            'titre_complet',        # TEXT
            'type_bien',           # VARCHAR(50)
            'type_offre',          # VARCHAR(20)
            'ville',               # VARCHAR(100)
            'quartier',            # VARCHAR(100)
            'surface_m2',          # FLOAT
            'prix_fcfa',           # DECIMAL(15,2)
            'prix_m2',             # DECIMAL(10,2) ‚≠ê INDICATEUR CL√â
            'latitude',            # DECIMAL(10,8)
            'longitude',           # DECIMAL(11,8)
            'source',              # VARCHAR(50)
            'date_publication',    # DATE
            'date_collecte',       # DATE
            'url_annonce',         # TEXT
            'url_photo',           # TEXT (NIVEAU 2)
            'statut'               # VARCHAR(20)
        ]
        
        # S√©lectionner uniquement les colonnes de la BDD
        df_export = df_clean[colonnes_bdd].copy()
        
        # G√©n√©rer timestamp pour le nom de fichier
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        
        if format == 'csv':
            filename = f'id_immobilier_clean_{timestamp}.csv'
            df_export.to_csv(filename, index=False, encoding='utf-8-sig')
            print(f"\n‚úÖ Export CSV: {filename}")
        
        elif format == 'excel':
            filename = f'id_immobilier_clean_{timestamp}.xlsx'
            with pd.ExcelWriter(filename, engine='openpyxl') as writer:
                # Feuille 1: Donn√©es nettoy√©es
                df_export.to_excel(writer, sheet_name='Donn√©es', index=False)
                
                # Feuille 2: Statistiques
                stats = self.generer_statistiques(df_clean)
                stats.to_excel(writer, sheet_name='Statistiques')
            
            print(f"\n‚úÖ Export Excel: {filename}")
        
        elif format == 'json':
            filename = f'id_immobilier_clean_{timestamp}.json'
            df_export.to_json(filename, orient='records', force_ascii=False, indent=2)
            print(f"\n‚úÖ Export JSON: {filename}")
        
        elif format == 'sql':
            filename = f'id_immobilier_insert_{timestamp}.sql'
            self.generer_insert_sql(df_export, filename)
            print(f"\n‚úÖ Export SQL: {filename}")
        
        return filename
    
    def generer_statistiques(self, df):
        """G√©n√©rer des statistiques pour Excel"""
        stats = {
            'Total lignes': len(df),
            'Prix moyen (FCFA)': df['prix_fcfa'].mean(),
            'Prix m√©dian (FCFA)': df['prix_fcfa'].median(),
            'Prix moyen au m¬≤ (FCFA)': df['prix_m2'].mean(),
            'Surface moyenne (m¬≤)': df['surface_m2'].mean(),
            'Terrains': (df['type_bien'] == 'Terrain').sum(),
            'Ventes': (df['type_offre'] == 'Vente').sum(),
            'Locations': (df['type_offre'] == 'Location').sum()
        }
        return pd.DataFrame([stats]).T.rename(columns={0: 'Valeur'})
    
    def generer_insert_sql(self, df, filename):
        """G√©n√©rer des requ√™tes INSERT SQL"""
        with open(filename, 'w', encoding='utf-8') as f:
            f.write("-- Script SQL pour ID Immobilier\n")
            f.write("-- G√©n√©r√© le: {}\n\n".format(datetime.now().strftime('%Y-%m-%d %H:%M:%S')))
            
            f.write("CREATE TABLE IF NOT EXISTS biens_immobiliers (\n")
            f.write("    id_bien VARCHAR(50) PRIMARY KEY,\n")
            f.write("    titre_complet TEXT,\n")
            f.write("    type_bien VARCHAR(50),\n")
            f.write("    type_offre VARCHAR(20),\n")
            f.write("    ville VARCHAR(100),\n")
            f.write("    quartier VARCHAR(100),\n")
            f.write("    surface_m2 FLOAT,\n")
            f.write("    prix_fcfa DECIMAL(15,2),\n")
            f.write("    prix_m2 DECIMAL(10,2),\n")
            f.write("    latitude DECIMAL(10,8),\n")
            f.write("    longitude DECIMAL(11,8),\n")
            f.write("    source VARCHAR(50),\n")
            f.write("    date_publication DATE,\n")
            f.write("    date_collecte DATE,\n")
            f.write("    url_annonce TEXT,\n")
            f.write("    url_photo TEXT,\n")
            f.write("    statut VARCHAR(20)\n")
            f.write(");\n\n")
            
            for _, row in df.iterrows():
                values = []
                for col in df.columns:
                    val = row[col]
                    if pd.isna(val) or val is None:
                        values.append('NULL')
                    elif isinstance(val, str):
                        clean_val = val.replace("'", "''")
                        values.append(f"'{clean_val}'")
                    else:
                        values.append(str(val))
                
                insert = f"INSERT INTO biens_immobiliers VALUES ({', '.join(values)});\n"
                f.write(insert)
    
    # ============================================
    # ANALYSES COMPL√âMENTAIRES
    # ============================================
    
    def analyser_par_quartier(self, df):
        """Analyse d√©taill√©e par quartier (pour l'indice immobilier)"""
        print("\n" + "="*60)
        print("üìç ANALYSE PAR QUARTIER")
        print("="*60)
        
        analyse = df[df['quartier'] != 'Non sp√©cifi√©'].groupby('quartier').agg({
            'prix_m2': ['mean', 'median', 'min', 'max', 'count'],
            'surface_m2': 'mean',
            'prix_fcfa': 'mean'
        }).round(0)
        
        analyse.columns = ['Prix/m¬≤ Moyen', 'Prix/m¬≤ M√©dian', 'Prix/m¬≤ Min', 
                          'Prix/m¬≤ Max', 'Nb Annonces', 'Surface Moy', 'Prix Moyen']
        
        # Trier par prix au m¬≤ d√©croissant
        analyse = analyse.sort_values('Prix/m¬≤ Moyen', ascending=False)
        
        print(analyse)
        return analyse
    
    def detecter_anomalies(self, df):
        """D√©tecter les prix aberrants (pour validation)"""
        print("\n" + "="*60)
        print("üîç D√âTECTION DES ANOMALIES")
        print("="*60)
        
        Q1 = df['prix_m2'].quantile(0.25)
        Q3 = df['prix_m2'].quantile(0.75)
        IQR = Q3 - Q1
        
        # Bornes IQR (m√©thode standard)
        borne_inf = Q1 - 1.5 * IQR
        borne_sup = Q3 + 1.5 * IQR
        
        anomalies = df[(df['prix_m2'] < borne_inf) | (df['prix_m2'] > borne_sup)]
        
        print(f"Nombre d'anomalies d√©tect√©es: {len(anomalies)}")
        print(f"Borne inf√©rieure: {borne_inf:,.0f} FCFA/m¬≤")
        print(f"Borne sup√©rieure: {borne_sup:,.0f} FCFA/m¬≤")
        
        if len(anomalies) > 0:
            print("\nExemples d'anomalies:")
            print(anomalies[['titre_complet', 'quartier', 'prix_m2', 'prix_fcfa', 'surface_m2']].head(10))
        
        return anomalies


# ============================================
# FONCTION PRINCIPALE D'UTILISATION
# ============================================

def main():
    """
    Fonction principale pour nettoyer les donn√©es Facebook Marketplace
    """
    
    print("="*60)
    print("üè† PROJET ID IMMOBILIER - NETTOYAGE DES DONN√âES")
    print("="*60)
    print()
    
    # 1. Charger les donn√©es
    print("üìÇ Chargement des donn√©es...")
    df = pd.read_csv('/mnt/user-data/uploads/1770856556826_dataset_test_2026-02-12_00-27-35-233.csv')
    print(f"   ‚úì {len(df)} lignes charg√©es\n")
    
    # 2. Initialiser le nettoyeur
    cleaner = IDImmobilierCleaner()
    
    # 3. Nettoyer les donn√©es
    df_clean = cleaner.nettoyer_dataset(df)
    
    # 4. Analyses compl√©mentaires
    if len(df_clean) > 0:
        # Analyse par quartier
        analyse_quartier = cleaner.analyser_par_quartier(df_clean)
        
        # D√©tection des anomalies
        anomalies = cleaner.detecter_anomalies(df_clean)
        
        # 5. Exports multiples
        print("\n" + "="*60)
        print("üíæ EXPORTS")
        print("="*60)
        
        cleaner.exporter_pour_bdd(df_clean, format='csv')
        cleaner.exporter_pour_bdd(df_clean, format='excel')
        cleaner.exporter_pour_bdd(df_clean, format='json')
        cleaner.exporter_pour_bdd(df_clean, format='sql')
        
        # 6. R√©sum√© final
        print("\n" + "="*60)
        print("‚úÖ NETTOYAGE TERMIN√â")
        print("="*60)
        print(f"üìä Donn√©es valides: {len(df_clean)}/{len(df)} ({len(df_clean)/len(df)*100:.1f}%)")
        print(f"üìç Quartiers identifi√©s: {(df_clean['quartier'] != 'Non sp√©cifi√©').sum()}")
        print(f"üí∞ Prix moyen au m¬≤: {df_clean['prix_m2'].mean():,.0f} FCFA")
        print("="*60)
    
    else:
        print("\n‚ö†Ô∏è ATTENTION: Aucune donn√©e valide apr√®s nettoyage")
        print("V√©rifiez vos donn√©es sources et les patterns d'extraction")


if __name__ == "__main__":
    main()